# ğŸ¡ House Price Prediction Pipeline

A **modular and production-oriented machine learning pipeline** for predicting house prices. This project is structured into two clear stages:

* **Stage 1:** Model training, hyperparameter tuning, and persistence
* **Stage 2:** Model loading and performance evaluation

---

## ğŸ“ Project Structure

```
house_price_pipeline/
â”‚
â”œâ”€â”€ main_stage1_tune.py         # Entry point: Train, tune, and save best models
â”œâ”€â”€ main_stage2_evaluate.py     # Entry point: Load saved models and evaluate
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ model_configs.py        # Models and hyperparameter grids
â”‚
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ preprocess.py           # Preprocessing steps and pipelines
â”‚   â””â”€â”€ trainer.py              # Core logic for model training and saving
â”‚
â”œâ”€â”€ registry/
â”‚   â””â”€â”€ (model_name).pkl        # Serialized best models saved after Stage 1
â”‚
â””â”€â”€ utils/
    â””â”€â”€ evaluation.py           # Evaluation metrics and model comparison logic
```

---

## ğŸ§  Key Features

* **Modular two-stage architecture** for clear separation of training and evaluation
* **Plug-and-play model registry** with versioned `.pkl` files
* **Configurable hyperparameter tuning** via `GridSearchCV`
* **Reusable preprocessing pipelines**
* **Robust evaluation metrics** including RÂ², RMSE, MAE, etc.

---

## ğŸ“¦ Dataset

The dataset is sourced via `kagglehub`:

```python
import kagglehub

# Automatically fetch the latest version
path = kagglehub.dataset_download("juhibhojani/house-price")
print("Path to dataset files:", path)
```

Make sure you have the necessary Kaggle API credentials set up before running this command.

---

## ğŸš€ Getting Started

### 1. **Install Requirements**

```bash
pip install -r requirements.txt
```

Make sure the following packages are included:

* `scikit-learn`
* `pandas`
* `numpy`
* `kagglehub`
* `joblib`

### 2. **Download Dataset**

Use the provided script or run the `kagglehub` snippet shown above to fetch the dataset.

---

## ğŸ—ï¸ Usage

### ğŸ”§ Stage 1: Train + Tune + Save

```bash
python main_stage1_tune.py
```

* Loads raw data
* Applies preprocessing (via `preprocess.py`)
* Performs grid search for each model in `model_configs.py`
* Saves the best model to `registry/`

### ğŸ“Š Stage 2: Load + Evaluate

```bash
python main_stage2_evaluate.py
```

* Loads saved models from `registry/`
* Reapplies preprocessing (on test/holdout set)
* Computes metrics using `utils/evaluation.py`

---

## ğŸ› ï¸ Customization

### âœ… Add a New Model

1. Define the model and its hyperparameter grid in `config/model_configs.py`
2. The tuning logic will automatically incorporate it during `main_stage1_tune.py`

### ğŸ“ Change Preprocessing

Edit or extend the pipeline in `pipeline/preprocess.py`. For example:

* Handle missing values
* Encode categorical variables
* Scale features

---

## ğŸ“ˆ Metrics Used

Implemented in `utils/evaluation.py`:

* **RÂ² Score**
* **Root Mean Squared Error (RMSE)**
* **Mean Absolute Error (MAE)**

Comparative plots or summary tables can be easily added in this module.

---

## âœ… Best Practices Followed

* **Separation of Concerns**: Training, configuration, and evaluation are cleanly separated
* **Versioning**: Models are saved and reused from a centralized registry
* **Config-Driven Design**: Model definitions and search spaces are abstracted in configs
* **Scalability**: Adding new models or datasets is straightforward

---

## ğŸ“€ Future Enhancements

* Add cross-validation visualization
* Integrate MLflow for model tracking
* Implement logging and exception handling
* Support CLI arguments for dataset path and mode

---

